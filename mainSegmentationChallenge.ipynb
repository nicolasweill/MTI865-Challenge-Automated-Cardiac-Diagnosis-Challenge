{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b07cf2f-b81d-43ef-907a-c49fed2d95ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from progressBar import printProgressBar\n",
    "\n",
    "import medicalDataLoader\n",
    "import argparse\n",
    "from utils import *\n",
    "\n",
    "from UNet_Base import *\n",
    "import random\n",
    "import torch\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e976350-3fd5-4406-8511-86a06a9b4494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342640ec",
   "metadata": {},
   "source": [
    "## Architecture du mod√®le (Bas√© sur UNet)\n",
    "En blanc le mod√®le de base, <span style=\"color: yellow;\">en jaune nos am√©liorations non termin√©es,</span> <span style=\"color: lightgreen;\">en vert les am√©liorations termin√©es</span>\n",
    "\n",
    "L‚Äôarchitecture baseline suit la structure classique d‚Äôun UNet : *Encoder --> Bottleneck --> Decoder* avec des skip connection skip connections entre blocs sym√©triques.\n",
    "\n",
    "### Chemin contractant : Encoder\n",
    "\n",
    "- On prend en entr√©e une image √† 1 canal et on compresse progressivement les features via 4 blocs encoder :\n",
    "    - `enc1` : 1 --> 4 canaux\n",
    "    - `enc2` : 4 --> 8 canaux\n",
    "    - `enc3` : 8 --> 16 canaux\n",
    "    - `enc4` : 16 --> 32 canaux (avec dropout pour la r√©gularisation)\n",
    "\n",
    "- Chaque bloc encoder effectue :\n",
    "    - une convolution 3√ó3\n",
    "    - une normalisation BatchNorm\n",
    "    - un ReLU\n",
    "    - <span style=\"color: yellow;\">un dropout optionnel (ajout pour r√©gularisation)</span>\n",
    "    - un MaxPool pour r√©duire la r√©solution spatiale\n",
    "\n",
    "Ces blocs permettent de capturer progressivement des caract√©ristiques de plus en plus complexes tout en compressant l‚Äôinformation.\n",
    "\n",
    "### Bottleneck : Couche centrale\n",
    "\n",
    "- On arrive au bottleneck (`center`) 32 --> 64 --> 32.\n",
    "\n",
    "C‚Äôest la zone o√π l‚Äôimage est repr√©sent√©e de mani√®re la plus compacte avant la reconstruction.\n",
    "\n",
    "### Bottleneck : Chemin expansif : Decoder\n",
    "\n",
    "- L‚Äôimage est ensuite reconstruite via 4 blocs decoder :\n",
    "    - `dec4` : 64 --> 32 --> 16\n",
    "    - `dec3` : 32 -6> 16 --> 8\n",
    "    - `dec2` : 16 --> 8 --> 4\n",
    "    - `dec1` : 2 convolutions 3*3 (4 --> 4 --> 4) \n",
    " \n",
    "- Chaque bloc decoder effectue : \n",
    "    - une convolution 3√ó3\n",
    "    - une normalisation BatchNorm\n",
    "    - un ReLU\n",
    "    - un upsampling avec ConvTranspose2d\n",
    "\n",
    "\n",
    "\n",
    "### Skip Connections\n",
    "\n",
    "Les sorties des blocs encoder sont concat√©n√©es aux blocs decoder correspondants. \n",
    "- pour r√©injecter des d√©tails locaux provenant de l‚Äôencoder, ce qui limite la perte d'information due au bottleneck\n",
    "\n",
    "### Couche finale\n",
    "\n",
    "La couche finale est une convolution 1√ó1 qui produit C logits pour les C classes --> on obtient un tenseur au format [B, C, H, W]\n",
    "\n",
    "- B\tTaille du batch\n",
    "- C\tNombre de classes \n",
    "- H\tHauteur de l‚Äôimage\n",
    "- W\tLargeur \n",
    "\n",
    "Pour **B** images, pour i allant de 0 √† B --> la sortie pour [image i] contient **C** matrices (= une matrice par classe) de dimension **H*W**, avec un logit (=output avant le softmax) pour chaque pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4483b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(pred, target, num_classes, eps=1e-7):\n",
    "    \"\"\"\n",
    "    Calcule le Dice score pour chaque classe\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pred : voir le markdown plus haut\n",
    "    target : format [B, H, W]\n",
    "        contient une seule valeur (et une seule matrice) par pixel :\n",
    "        (0=background, 1=classe 1, 2=classe 2, 3=classe 3)\n",
    "    num_classes : int\n",
    "        nombre de classes - incluant le background\n",
    "    eps : float\n",
    "        petite valeur pour √©viter la division par z√©ro\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dice_per_class : tensor\n",
    "        tensor contenant le dice score pour chaque classe (dim [num_classes])\n",
    "    \"\"\"\n",
    "    pred_classes = torch.argmax(pred, dim=1)  # retourne une pred par pixel au format [B, H, W]\n",
    "\n",
    "    dice_per_class = []\n",
    "    # on itere sur toutes les classes pour\n",
    "    for c in range(num_classes):\n",
    "        # cr√©ation de masques binaires pour la classe c pour pred et target\n",
    "        pred_c = (pred_classes == c).float()\n",
    "        target_c = (target == c).float() \n",
    "\n",
    "        intersection = (pred_c * target_c).sum() # ne donne 1 que si la pr√©dition et  la target correspondent\n",
    "        union = pred_c.sum() + target_c.sum() # la somme des pixels pr√©dits + la somme des pixels r√©els\n",
    "\n",
    "        dice = (2 * intersection + eps) / (union + eps)\n",
    "        dice_per_class.append(dice)\n",
    "\n",
    "    # retoune un tensor de dimension [num_classes]\n",
    "    return torch.stack(dice_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220c7dcc-8438-454d-97b1-8e989a7b8f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def runTraining():\n",
    "\n",
    "    print('-' * 40)\n",
    "    print('~~~~~~~~  Starting the training... ~~~~~~')\n",
    "    print('-' * 40)\n",
    "\n",
    "    ## DEFINE HYPERPARAMETERS (batch_size > 1)\n",
    "    batch_size = 4\n",
    "    batch_size_val = 4 \n",
    "    lr = 0.01    # Learning Rate\n",
    "    epoch = 10 # Number of epochs\n",
    "    \n",
    "    root_dir = './Data/'\n",
    "\n",
    "    print(' Dataset: {} '.format(root_dir))\n",
    "\n",
    "    ## DEFINE THE TRANSFORMATIONS TO DO AND THE VARIABLES FOR TRAINING AND VALIDATION\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    mask_transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_set_full = medicalDataLoader.MedicalImageDataset('train',\n",
    "                                                      root_dir,\n",
    "                                                      transform=transform,\n",
    "                                                      mask_transform=mask_transform,\n",
    "                                                      augment=False,\n",
    "                                                      equalize=False)\n",
    "\n",
    "    train_loader_full = DataLoader(train_set_full,\n",
    "                              batch_size=batch_size,\n",
    "                              worker_init_fn=np.random.seed(0),\n",
    "                              num_workers=0,\n",
    "                              shuffle=True)\n",
    "\n",
    "\n",
    "    val_set = medicalDataLoader.MedicalImageDataset('val',\n",
    "                                                    root_dir,\n",
    "                                                    transform=transform,\n",
    "                                                    mask_transform=mask_transform,\n",
    "                                                    equalize=False)\n",
    "\n",
    "    val_loader = DataLoader(val_set,\n",
    "                            batch_size=batch_size_val,\n",
    "                            worker_init_fn=np.random.seed(0),\n",
    "                            num_workers=0,\n",
    "                            shuffle=False)\n",
    "\n",
    "    # definition de la fonction de validation\n",
    "    def validate(model, loader, criterion, num_classes):\n",
    "        \"\"\"\n",
    "        Evalue les performances du mod√®le sur un ensemble de validation (dice + loss)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : torch.nn.Module\n",
    "            Le mod√®le √† √©valuer\n",
    "        loader : torch.utils.data.DataLoader\n",
    "            Dataloader avec les images + labels pour la validation\n",
    "        criterion : callable\n",
    "            Fonction de perte utilis√©e pour calculer le loss \n",
    "        num_classes : int\n",
    "            Nombre de classes de segmentation pour le dice\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        avg_loss : float\n",
    "            Loss moyen sur l‚Äôensemble du dataset\n",
    "        dice_mean : numpy.ndarray\n",
    "            Tableau de dim [num_classes] contenant la moyenne du dice \n",
    "        pour chaque classe de segmentation\n",
    "\n",
    "        \"\"\"\n",
    "        model.eval() # passe en mode √©valuation\n",
    "        total_loss = 0.0\n",
    "        dice_total = []\n",
    "\n",
    "        with torch.no_grad(): # pas de calcul de gradient -> pas necessaire ici et plus rapide \n",
    "            for images, labels, _ in loader:\n",
    "                images = to_var(images)\n",
    "                labels = to_var(labels)\n",
    "\n",
    "                outputs = model(images) # prediction du mod√®le\n",
    "                segmentation_classes = getTargetSegmentation(labels)\n",
    "\n",
    "                loss = criterion(outputs, segmentation_classes)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                dice = dice_score(outputs, segmentation_classes, num_classes)\n",
    "                dice_total.append(dice.cpu().numpy())\n",
    "\n",
    "        dice_mean = np.mean(np.array(dice_total), axis=0)  # dice pour chaque classe\n",
    "        return total_loss / len(loader), dice_mean\n",
    "\n",
    "    ## INITIALIZE YOUR MODEL\n",
    "    num_classes = 4 # NUMBER OF CLASSES\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "    modelName = 'Test_Model'\n",
    "    print(\" Model Name: {}\".format(modelName))\n",
    "\n",
    "    ## CREATION OF YOUR MODEL\n",
    "    net = UNet(num_classes)\n",
    "\n",
    "    print(\"Total params: {0:,}\".format(sum(p.numel() for p in net.parameters() if p.requires_grad)))\n",
    "\n",
    "    # DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "    softMax = torch.nn.Softmax(dim=1)\n",
    "    CE_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    ## PUT EVERYTHING IN GPU RESOURCES    \n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "        softMax.cuda()\n",
    "        CE_loss.cuda()\n",
    "\n",
    "    ## DEFINE YOUR OPTIMIZER\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    ### To save statistics ####\n",
    "    lossTotalTraining = []\n",
    "    Best_loss_val = 1000\n",
    "    BestEpoch = 0\n",
    "    \n",
    "    directory = 'Results/Statistics/' + modelName\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "    if os.path.exists(directory)==False:\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    ## START THE TRAINING\n",
    "    \n",
    "    ## FOR EACH EPOCH\n",
    "    for i in range(epoch):\n",
    "        net.train() # mod√®le en mode entrainement\n",
    "        lossEpoch = []\n",
    "        DSCEpoch = []\n",
    "        DSCEpoch_w = []\n",
    "        num_batches = len(train_loader_full)\n",
    "        \n",
    "        ## FOR EACH BATCH\n",
    "        for j, data in enumerate(train_loader_full):\n",
    "            ### Set to zero all the gradients\n",
    "            net.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ## GET IMAGES, LABELS and IMG NAMES\n",
    "            images, labels, img_names = data\n",
    "\n",
    "            ### From numpy to torch variables\n",
    "            labels = to_var(labels)\n",
    "            images = to_var(images)\n",
    "\n",
    "            ################### Train ###################\n",
    "            #-- The CNN makes its predictions (forward pass)\n",
    "            net_predictions = net(images)\n",
    "\n",
    "            #-- Compute the losses --#\n",
    "            # THIS FUNCTION IS TO CONVERT LABELS TO A FORMAT TO BE USED IN THIS CODE\n",
    "            segmentation_classes = getTargetSegmentation(labels)\n",
    "            \n",
    "            # COMPUTE THE LOSS\n",
    "            CE_loss_value = CE_loss(net_predictions, segmentation_classes) # XXXXXX and YYYYYYY are your inputs for the CE\n",
    "            lossTotal = CE_loss_value\n",
    "\n",
    "            # DO THE STEPS FOR BACKPROP (two things to be done in pytorch)\n",
    "            \n",
    "            # THIS IS JUST TO VISUALIZE THE TRAINING \n",
    "            lossEpoch.append(lossTotal.cpu().data.numpy())\n",
    "            printProgressBar(j + 1, num_batches,\n",
    "                             prefix=\"[Training] Epoch: {} \".format(i),\n",
    "                             length=15,\n",
    "                             suffix=\" Loss: {:.4f}, \".format(lossTotal))\n",
    "\n",
    "        lossEpoch = np.asarray(lossEpoch)\n",
    "        lossEpoch = lossEpoch.mean()\n",
    "\n",
    "        lossTotalTraining.append(lossEpoch)\n",
    "\n",
    "        # ---- DICE SCORE ---- #\n",
    "        with torch.no_grad():\n",
    "            dice = dice_score(net_predictions, segmentation_classes, num_classes)\n",
    "            DSCEpoch.append(dice.cpu().numpy())\n",
    "\n",
    "\n",
    "        printProgressBar(num_batches, num_batches,\n",
    "                             done=\"[Training] Epoch: {}, LossG: {:.4f}\".format(i,lossEpoch))\n",
    "        \n",
    "        # VALIDATION PHASE \n",
    "        val_loss, val_dice = validate(net, val_loader, CE_loss, num_classes)\n",
    "        print(f\"[Validation] Epoch: {i}, Loss: {val_loss:.4f}, Dice: {val_dice}\")\n",
    "\n",
    "        # SAUVEGARDE DU MEILLEUR MODELE SELON LE LOSS DE VALIDATION\n",
    "        if val_loss < Best_loss_val:\n",
    "            Best_loss_val = val_loss\n",
    "            BestEpoch = i\n",
    "\n",
    "            if not os.path.exists('./models/' + modelName):\n",
    "                os.makedirs('./models/' + modelName)\n",
    "\n",
    "            torch.save(net.state_dict(), './models/' + modelName + '/' + str(i) + '_Epoch')\n",
    "            print(f\"Best model updated at epoch {i} (val_loss={val_loss:.4f})\")\n",
    "\n",
    "    print(\"\\n----------------------------------------\")\n",
    "    print(f\"Best model found at epoch {BestEpoch} with validation loss = {Best_loss_val:.4f}\")\n",
    "    print(\"----------------------------------------\\n\")\n",
    "\n",
    "\n",
    "        # ## THIS IS HOW YOU WILL SAVE THE TRAINED MODELS AFTER EACH EPOCH. \n",
    "        # ## WARNING!!!!! YOU DON'T WANT TO SAVE IT AT EACH EPOCH, BUT ONLY WHEN THE MODEL WORKS BEST ON THE VALIDATION SET!!\n",
    "        # if not os.path.exists('./models/' + modelName):\n",
    "        #         os.makedirs('./models/' + modelName)\n",
    "\n",
    "        #     torch.save(net.state_dict(), './models/' + modelName + '/' + str(i) + '_Epoch')\n",
    "            \n",
    "        # np.save(os.path.join(directory, 'Losses.npy'), lossTotalTraining)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a381872",
   "metadata": {},
   "source": [
    "√Ä chaque epoch, le mod√®le passe successivement par :\n",
    "\n",
    "- une phase d'entra√Ænement (LossG),\n",
    "- une phase de validation (val_loss),\n",
    "- une v√©rification si le mod√®le est le meilleur jusqu‚Äôici.\n",
    "\n",
    "Dans cette fonction, nous avons ajout√© :\n",
    "<p style=\"color:lightgreen\">\n",
    "- Une fonction pour √©valuer le mod√®le √† chaque epoch<br>\n",
    "- Une fonction pour calculer le Dice score\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f81713-4c18-4dd3-bc72-35dd8f30a339",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "~~~~~~~~  Starting the training... ~~~~~~\n",
      "----------------------------------------\n",
      " Dataset: ./Data/ \n",
      "~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\n",
      " Model Name: Test_Model\n",
      "Total params: 60,664\n",
      "~~~~~~~~~~~ Starting the training ~~~~~~~~~~\n",
      "[Training] Epoch: 0 [DONE]                                 \n",
      "[Training] Epoch: 0, LossG: 1.8079                                                                           \n",
      "[Validation] Epoch: 0, Loss: 1.6403, Dice: [0.25092205 0.00207371 0.0196559  0.014097  ]\n",
      "Best model updated at epoch 0 (val_loss=1.6403)\n",
      "[Training] Epoch: 1 [DONE]                                 \n",
      "[Training] Epoch: 1, LossG: 1.8074                                                                           \n",
      "[Validation] Epoch: 1, Loss: 1.7036, Dice: [0.3067482  0.00233595 0.01749299 0.01859846]\n",
      "[Training] Epoch: 2 [DONE]                                 \n",
      "[Training] Epoch: 2, LossG: 1.8084                                                                           \n",
      "[Validation] Epoch: 2, Loss: 1.7244, Dice: [0.31170657 0.00232761 0.01811041 0.01895414]\n",
      "[Training] Epoch: 3 [DONE]                                 \n",
      "[Training] Epoch: 3, LossG: 1.8080                                                                           \n",
      "[Validation] Epoch: 3, Loss: 1.7109, Dice: [0.31841066 0.0024244  0.01792125 0.01853519]\n",
      "[Training] Epoch: 4 [DONE]                                 \n",
      "[Training] Epoch: 4, LossG: 1.8077                                                                           \n",
      "[Validation] Epoch: 4, Loss: 1.7168, Dice: [0.31469285 0.0024011  0.01815285 0.01893213]\n",
      "[Training] Epoch: 5 [DONE]                                 \n",
      "[Training] Epoch: 5, LossG: 1.8080                                                                           \n",
      "[Validation] Epoch: 5, Loss: 1.7026, Dice: [0.31832215 0.00224779 0.01787625 0.01865341]\n",
      "[Training] Epoch: 6 [DONE]                                 \n",
      "[Training] Epoch: 6, LossG: 1.8076                                                                           \n",
      "[Validation] Epoch: 6, Loss: 1.7147, Dice: [0.31120008 0.00240135 0.01793131 0.01896923]\n",
      "[Training] Epoch: 7 [DONE]                                 \n",
      "[Training] Epoch: 7, LossG: 1.8081                                                                           \n",
      "[Validation] Epoch: 7, Loss: 1.7181, Dice: [0.31382254 0.00246174 0.01809547 0.01898301]\n",
      "[Training] Epoch: 8 [DONE]                                 \n",
      "[Training] Epoch: 8, LossG: 1.8080                                                                           \n",
      "[Validation] Epoch: 8, Loss: 1.7346, Dice: [0.31152222 0.0024574  0.01810325 0.01937517]\n",
      "[Training] Epoch: 9 [DONE]                                 \n",
      "[Training] Epoch: 9, LossG: 1.8074                                                                           \n",
      "[Validation] Epoch: 9, Loss: 1.7242, Dice: [0.31340823 0.00263156 0.01812817 0.01906803]\n",
      "\n",
      "----------------------------------------\n",
      "Best model found at epoch 0 with validation loss = 1.6403\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runTraining()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b19933",
   "metadata": {},
   "source": [
    "On observe que la perte d‚Äôentra√Ænement reste stable autour de 1.07 pour toutes les √©poques :\n",
    "- Cela indique que le mod√®le baseline apprend tr√®s peu, ou pas du tout.\n",
    "- Le mod√®le apprend un peu au d√©but (jusqu'√† epoch : 6), puis commence √† stagner ou l√©g√®rement sur-apprendre\n",
    "- Meilleur mod√®le = epoch 6\n",
    "\n",
    "A faire ensuite :\n",
    "- Am√©liore le mod√®le\n",
    "- faire un dice score\n",
    "- visualiser les diff√©rentes √©tapes/pr√©dictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db98de9b",
   "metadata": {},
   "source": [
    "**Selon l'ami le chat :**\n",
    "\n",
    "üîç Que v√©rifier maintenant ?\n",
    "\n",
    "Parce que ton loss stable est louche, tu devrais v√©rifier :\n",
    "\n",
    "‚úî 1. getTargetSegmentation(labels)\n",
    "\n",
    "Est-ce que √ßa renvoie bien un tenseur [B,H,W] d'entiers (classes) ?\n",
    "\n",
    "‚úî 2. Les labels contiennent plusieurs classes ?\n",
    "\n",
    "Si tout est 0 ‚Üí CE ~1.07 est normal.\n",
    "\n",
    "‚úî 3. Le learning rate\n",
    "\n",
    "lr = 0.01 est assez agressif pour UNet.\n",
    "Essaie 0.001 ou 0.0001.\n",
    "\n",
    "‚úî 4. Visualiser quelques pr√©dictions\n",
    "\n",
    "Pour v√©rifier que les masques pr√©vus ne sont pas tous pareils."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
