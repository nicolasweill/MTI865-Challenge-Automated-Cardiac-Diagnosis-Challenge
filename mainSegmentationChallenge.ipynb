{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b07cf2f-b81d-43ef-907a-c49fed2d95ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from progressBar import printProgressBar\n",
    "\n",
    "import medicalDataLoader\n",
    "import argparse\n",
    "from utils import *\n",
    "\n",
    "from UNet_Base import *\n",
    "import random\n",
    "import torch\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e976350-3fd5-4406-8511-86a06a9b4494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50df2b49",
   "metadata": {},
   "source": [
    "**Format [B, C, H, W]** :\n",
    "\n",
    "- B\tTaille du batch\n",
    "- C\tNombre de classes \n",
    "- H\tHauteur de lâ€™image\n",
    "- W\tLargeur \n",
    "\n",
    "--> pred est au format [B, C, H, W] ie :\n",
    "- Pour **B** images, pour i allant de 0 Ã  B --> pred[image i] contient **C** matrices (= une matrice par classe) de dimension **H*W**, avec un logit (=output avant le softmax) pour chaque pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4483b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(pred, target, num_classes, eps=1e-7):\n",
    "    \"\"\"\n",
    "    pred: voir le markdown plus haut   \n",
    "    target: format [B, H, W] --> contient une seule valeur (et une seule matrice) par pixel : \n",
    "            (0=background, 1=classe 1, 2=classe 2, 3=classe 3)\n",
    "    \"\"\"\n",
    "    pred_classes = torch.argmax(pred, dim=1)  # retourne une pred par pixel au format [B, H, W]\n",
    "\n",
    "    dice_per_class = []\n",
    "    for c in range(num_classes):\n",
    "        pred_c = (pred_classes == c).float()\n",
    "        target_c = (target == c).float()\n",
    "\n",
    "        intersection = (pred_c * target_c).sum()\n",
    "        union = pred_c.sum() + target_c.sum()\n",
    "\n",
    "        dice = (2 * intersection + eps) / (union + eps)\n",
    "        dice_per_class.append(dice)\n",
    "\n",
    "    # retoune un tensor shape [num_classes]\n",
    "    return torch.stack(dice_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "220c7dcc-8438-454d-97b1-8e989a7b8f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def runTraining():\n",
    "    print('-' * 40)\n",
    "    print('~~~~~~~~  Starting the training... ~~~~~~')\n",
    "    print('-' * 40)\n",
    "\n",
    "    ## DEFINE HYPERPARAMETERS (batch_size > 1)\n",
    "    batch_size = 4\n",
    "    batch_size_val = 4 \n",
    "    lr = 0.01    # Learning Rate\n",
    "    epoch = 10 # Number of epochs\n",
    "    \n",
    "    root_dir = './Data/'\n",
    "\n",
    "    print(' Dataset: {} '.format(root_dir))\n",
    "\n",
    "    ## DEFINE THE TRANSFORMATIONS TO DO AND THE VARIABLES FOR TRAINING AND VALIDATION\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    mask_transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_set_full = medicalDataLoader.MedicalImageDataset('train',\n",
    "                                                      root_dir,\n",
    "                                                      transform=transform,\n",
    "                                                      mask_transform=mask_transform,\n",
    "                                                      augment=False,\n",
    "                                                      equalize=False)\n",
    "\n",
    "    train_loader_full = DataLoader(train_set_full,\n",
    "                              batch_size=batch_size,\n",
    "                              worker_init_fn=np.random.seed(0),\n",
    "                              num_workers=0,\n",
    "                              shuffle=True)\n",
    "\n",
    "\n",
    "    val_set = medicalDataLoader.MedicalImageDataset('val',\n",
    "                                                    root_dir,\n",
    "                                                    transform=transform,\n",
    "                                                    mask_transform=mask_transform,\n",
    "                                                    equalize=False)\n",
    "\n",
    "    val_loader = DataLoader(val_set,\n",
    "                            batch_size=batch_size_val,\n",
    "                            worker_init_fn=np.random.seed(0),\n",
    "                            num_workers=0,\n",
    "                            shuffle=False)\n",
    "\n",
    "    # VALIDATION FUNCTION\n",
    "    def validate(model, loader, criterion, num_classes):\n",
    "        model.eval()\n",
    "        total_loss = 0.0\n",
    "        dice_total = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels, _ in loader:\n",
    "                images = to_var(images)\n",
    "                labels = to_var(labels)\n",
    "\n",
    "                outputs = model(images)\n",
    "                segmentation_classes = getTargetSegmentation(labels)\n",
    "\n",
    "                loss = criterion(outputs, segmentation_classes)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                dice = dice_score(outputs, segmentation_classes, num_classes)\n",
    "                dice_total.append(dice.cpu().numpy())\n",
    "\n",
    "        dice_mean = np.mean(np.array(dice_total), axis=0)  # dice pour chaque classe\n",
    "        return total_loss / len(loader), dice_mean\n",
    "\n",
    "\n",
    "\n",
    "    ## INITIALIZE YOUR MODEL\n",
    "    num_classes = 4 # NUMBER OF CLASSES\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "    modelName = 'Test_Model'\n",
    "    print(\" Model Name: {}\".format(modelName))\n",
    "\n",
    "    ## CREATION OF YOUR MODEL\n",
    "    net = UNet(num_classes)\n",
    "\n",
    "    print(\"Total params: {0:,}\".format(sum(p.numel() for p in net.parameters() if p.requires_grad)))\n",
    "\n",
    "    # DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "    softMax = torch.nn.Softmax(dim=1)\n",
    "    CE_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    ## PUT EVERYTHING IN GPU RESOURCES    \n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "        softMax.cuda()\n",
    "        CE_loss.cuda()\n",
    "\n",
    "    ## DEFINE YOUR OPTIMIZER\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    ### To save statistics ####\n",
    "    lossTotalTraining = []\n",
    "    Best_loss_val = 1000\n",
    "    BestEpoch = 0\n",
    "    \n",
    "    directory = 'Results/Statistics/' + modelName\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "    if os.path.exists(directory)==False:\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    ## START THE TRAINING\n",
    "    \n",
    "    ## FOR EACH EPOCH\n",
    "    for i in range(epoch):\n",
    "        net.train()\n",
    "        lossEpoch = []\n",
    "        DSCEpoch = []\n",
    "        DSCEpoch_w = []\n",
    "        num_batches = len(train_loader_full)\n",
    "        \n",
    "        ## FOR EACH BATCH\n",
    "        for j, data in enumerate(train_loader_full):\n",
    "            ### Set to zero all the gradients\n",
    "            net.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ## GET IMAGES, LABELS and IMG NAMES\n",
    "            images, labels, img_names = data\n",
    "\n",
    "            ### From numpy to torch variables\n",
    "            labels = to_var(labels)\n",
    "            images = to_var(images)\n",
    "\n",
    "            ################### Train ###################\n",
    "            #-- The CNN makes its predictions (forward pass)\n",
    "            net_predictions = net(images)\n",
    "\n",
    "            #-- Compute the losses --#\n",
    "            # THIS FUNCTION IS TO CONVERT LABELS TO A FORMAT TO BE USED IN THIS CODE\n",
    "            segmentation_classes = getTargetSegmentation(labels)\n",
    "            \n",
    "            # COMPUTE THE LOSS\n",
    "            CE_loss_value = CE_loss(net_predictions, segmentation_classes) # XXXXXX and YYYYYYY are your inputs for the CE\n",
    "            lossTotal = CE_loss_value\n",
    "\n",
    "            # DO THE STEPS FOR BACKPROP (two things to be done in pytorch)\n",
    "            \n",
    "            # THIS IS JUST TO VISUALIZE THE TRAINING \n",
    "            lossEpoch.append(lossTotal.cpu().data.numpy())\n",
    "            printProgressBar(j + 1, num_batches,\n",
    "                             prefix=\"[Training] Epoch: {} \".format(i),\n",
    "                             length=15,\n",
    "                             suffix=\" Loss: {:.4f}, \".format(lossTotal))\n",
    "\n",
    "        lossEpoch = np.asarray(lossEpoch)\n",
    "        lossEpoch = lossEpoch.mean()\n",
    "\n",
    "        lossTotalTraining.append(lossEpoch)\n",
    "\n",
    "        # ---- DICE SCORE ---- #\n",
    "        with torch.no_grad():\n",
    "            dice = dice_score(net_predictions, segmentation_classes, num_classes)\n",
    "            DSCEpoch.append(dice.cpu().numpy())\n",
    "\n",
    "\n",
    "        printProgressBar(num_batches, num_batches,\n",
    "                             done=\"[Training] Epoch: {}, LossG: {:.4f}\".format(i,lossEpoch))\n",
    "        \n",
    "        # VALIDATION PHASE \n",
    "        val_loss, val_dice = validate(net, val_loader, CE_loss, num_classes)\n",
    "        print(f\"[Validation] Epoch: {i}, Loss: {val_loss:.4f}, Dice: {val_dice}\")\n",
    "\n",
    "        # SAVE BEST MODEL\n",
    "        if val_loss < Best_loss_val:\n",
    "            Best_loss_val = val_loss\n",
    "            BestEpoch = i\n",
    "\n",
    "            if not os.path.exists('./models/' + modelName):\n",
    "                os.makedirs('./models/' + modelName)\n",
    "\n",
    "            torch.save(net.state_dict(), './models/' + modelName + '/' + str(i) + '_Epoch')\n",
    "            print(f\"Best model updated at epoch {i} (val_loss={val_loss:.4f})\")\n",
    "\n",
    "    print(\"\\n----------------------------------------\")\n",
    "    print(f\"Best model found at epoch {BestEpoch} with validation loss = {Best_loss_val:.4f}\")\n",
    "    print(\"----------------------------------------\\n\")\n",
    "\n",
    "\n",
    "        # ## THIS IS HOW YOU WILL SAVE THE TRAINED MODELS AFTER EACH EPOCH. \n",
    "        # ## WARNING!!!!! YOU DON'T WANT TO SAVE IT AT EACH EPOCH, BUT ONLY WHEN THE MODEL WORKS BEST ON THE VALIDATION SET!!\n",
    "        # if not os.path.exists('./models/' + modelName):\n",
    "        #         os.makedirs('./models/' + modelName)\n",
    "\n",
    "        #     torch.save(net.state_dict(), './models/' + modelName + '/' + str(i) + '_Epoch')\n",
    "            \n",
    "        # np.save(os.path.join(directory, 'Losses.npy'), lossTotalTraining)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a381872",
   "metadata": {},
   "source": [
    "Ã€ chaque epoch, le modÃ¨le passe successivement par :\n",
    "\n",
    "- une phase d'entraÃ®nement (LossG),\n",
    "- une phase de validation (val_loss),\n",
    "- une vÃ©rification si le modÃ¨le est le meilleur jusquâ€™ici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f81713-4c18-4dd3-bc72-35dd8f30a339",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "~~~~~~~~  Starting the training... ~~~~~~\n",
      "----------------------------------------\n",
      " Dataset: ./Data/ \n",
      "~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\n",
      " Model Name: Test_Model\n",
      "Total params: 60,664\n",
      "~~~~~~~~~~~ Starting the training ~~~~~~~~~~\n",
      "[Training] Epoch: 0 [DONE]                                 \n",
      "[Training] Epoch: 0, LossG: 1.8079                                                                           \n",
      "[Validation] Epoch: 0, Loss: 1.6403, Dice: [0.25092205 0.00207371 0.0196559  0.014097  ]\n",
      "Best model updated at epoch 0 (val_loss=1.6403)\n",
      "[Training] Epoch: 1 [DONE]                                 \n",
      "[Training] Epoch: 1, LossG: 1.8074                                                                           \n",
      "[Validation] Epoch: 1, Loss: 1.7036, Dice: [0.3067482  0.00233595 0.01749299 0.01859846]\n",
      "[Training] Epoch: 2 [DONE]                                 \n",
      "[Training] Epoch: 2, LossG: 1.8084                                                                           \n",
      "[Validation] Epoch: 2, Loss: 1.7244, Dice: [0.31170657 0.00232761 0.01811041 0.01895414]\n",
      "[Training] Epoch: 3 [DONE]                                 \n",
      "[Training] Epoch: 3, LossG: 1.8080                                                                           \n",
      "[Validation] Epoch: 3, Loss: 1.7109, Dice: [0.31841066 0.0024244  0.01792125 0.01853519]\n",
      "[Training] Epoch: 4 [DONE]                                 \n",
      "[Training] Epoch: 4, LossG: 1.8077                                                                           \n",
      "[Validation] Epoch: 4, Loss: 1.7168, Dice: [0.31469285 0.0024011  0.01815285 0.01893213]\n",
      "[Training] Epoch: 5 [DONE]                                 \n",
      "[Training] Epoch: 5, LossG: 1.8080                                                                           \n",
      "[Validation] Epoch: 5, Loss: 1.7026, Dice: [0.31832215 0.00224779 0.01787625 0.01865341]\n",
      "[Training] Epoch: 6 [DONE]                                 \n",
      "[Training] Epoch: 6, LossG: 1.8076                                                                           \n",
      "[Validation] Epoch: 6, Loss: 1.7147, Dice: [0.31120008 0.00240135 0.01793131 0.01896923]\n",
      "[Training] Epoch: 7 [DONE]                                 \n",
      "[Training] Epoch: 7, LossG: 1.8081                                                                           \n",
      "[Validation] Epoch: 7, Loss: 1.7181, Dice: [0.31382254 0.00246174 0.01809547 0.01898301]\n",
      "[Training] Epoch: 8 [DONE]                                 \n",
      "[Training] Epoch: 8, LossG: 1.8080                                                                           \n",
      "[Validation] Epoch: 8, Loss: 1.7346, Dice: [0.31152222 0.0024574  0.01810325 0.01937517]\n",
      "[Training] Epoch: 9 [DONE]                                 \n",
      "[Training] Epoch: 9, LossG: 1.8074                                                                           \n",
      "[Validation] Epoch: 9, Loss: 1.7242, Dice: [0.31340823 0.00263156 0.01812817 0.01906803]\n",
      "\n",
      "----------------------------------------\n",
      "Best model found at epoch 0 with validation loss = 1.6403\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runTraining()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b19933",
   "metadata": {},
   "source": [
    "On observe que la perte dâ€™entraÃ®nement reste stable autour de 1.07 pour toutes les Ã©poques :\n",
    "- Cela indique que le modÃ¨le baseline apprend trÃ¨s peu, ou pas du tout.\n",
    "- Le modÃ¨le apprend un peu au dÃ©but (jusqu'Ã  epoch : 6), puis commence Ã  stagner ou lÃ©gÃ¨rement sur-apprendre\n",
    "- Meilleur modÃ¨le = epoch 6\n",
    "\n",
    "A faire ensuite :\n",
    "- AmÃ©liore le modÃ¨le\n",
    "- faire un dice score\n",
    "- visualiser les diffÃ©rentes Ã©tapes/prÃ©dictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db98de9b",
   "metadata": {},
   "source": [
    "**Selon l'ami le chat :**\n",
    "\n",
    "ðŸ” Que vÃ©rifier maintenant ?\n",
    "\n",
    "Parce que ton loss stable est louche, tu devrais vÃ©rifier :\n",
    "\n",
    "âœ” 1. getTargetSegmentation(labels)\n",
    "\n",
    "Est-ce que Ã§a renvoie bien un tenseur [B,H,W] d'entiers (classes) ?\n",
    "\n",
    "âœ” 2. Les labels contiennent plusieurs classes ?\n",
    "\n",
    "Si tout est 0 â†’ CE ~1.07 est normal.\n",
    "\n",
    "âœ” 3. Le learning rate\n",
    "\n",
    "lr = 0.01 est assez agressif pour UNet.\n",
    "Essaie 0.001 ou 0.0001.\n",
    "\n",
    "âœ” 4. Visualiser quelques prÃ©dictions\n",
    "\n",
    "Pour vÃ©rifier que les masques prÃ©vus ne sont pas tous pareils."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
